{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720f49d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you do not need to run, this code is for presetitnh \n",
    "import dask.dataframe as dd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "files_v1 = [\n",
    "    \"../data/commitinfo/provider_authz_v1_commit.parquet\",\n",
    "    \"../data/commitinfo/req_auth_v1_commit.parquet\",\n",
    "    \"../data/commitinfo/http_authz_v1_commit.parquet\",\n",
    "    \"../data/commitinfo/tcp_authz_v1_commit.parquet\",\n",
    "    \"../data/commitinfo/jwt_authz_v1_commit.parquet\",\n",
    "    \"../data/commitinfo/provider_authz_v1_commit.parquet\",\n",
    "    \"../data/commitinfo/ingress_authz_ip_v1_commit.parquet\",\n",
    "    \"../data/commitinfo/ingress_authz_remote_ip_v1_commit.parquet\",\n",
    "    \"../data/commitinfo/mtls_strict_v1_commit.parquet\",\n",
    "    \"../data/commitinfo/mtls_permissive_v1_commit.parquet\",\n",
    "    \"../data/commitinfo/mtls_disable_v1_commit.parquet\",\n",
    "]\n",
    "\n",
    "files_v1beta1 = [\n",
    "    \"../data/commitinfo/peer_auth_v1beta1_commit.parquet\",\n",
    "    \"../data/commitinfo/req_auth_v1beta1_commit.parquet\",\n",
    "    \"../data/commitinfo/http_authz_v1beta1_commit.parquet\",\n",
    "    \"../data/commitinfo/tcp_authz_v1beta1_commit.parquet\",\n",
    "    \"../data/commitinfo/jwt_authz_v1beta1_commit.parquet\",\n",
    "    \"../data/commitinfo/provider_authz_v1beta1_commit.parquet\",\n",
    "    \"../data/commitinfo/ingress_authz_ip_v1beta1_commit.parquet\",\n",
    "    \"../data/commitinfo/ingress_authz_remote_ip_v1beta1_commit.parquet\",\n",
    "    \"../data/commitinfo/mtls_strict_v1beta1_commit.parquet\",\n",
    "    \"../data/commitinfo/mtls_permissive_v1beta1_commit.parquet\",\n",
    "    \"../data/commitinfo/mtls_disable_v1beta1_commit.parquet\",\n",
    "]\n",
    "\n",
    "files_v1alpha1 = [\n",
    "    \"../data/commitinfo/peer_auth_v1alpha1_commit.parquet\",\n",
    "    \"../data/commitinfo/req_auth_v1alpha1_commit.parquet\",\n",
    "    \"../data/commitinfo/any_authz_v1alpha1_commit.parquet\",\n",
    "    \"../data/commitinfo/mtls_strict_v1alpha1_commit.parquet\",\n",
    "    \"../data/commitinfo/mtls_permissive_v1alpha1_commit.parquet\",\n",
    "]\n",
    "\n",
    "\n",
    "processed_dirs = {\n",
    "    \"v1\": \"../data/processed/v1\",\n",
    "    \"v1beta1\": \"../data/processed/v1beta1\",\n",
    "    \"v1alpha1\": \"../data/processed/v1alpha1\",\n",
    "}\n",
    "\n",
    "final_dirs = {\n",
    "    \"v1\": \"../data/final/v1\",\n",
    "    \"v1beta1\": \"../data/final/v1beta1\",\n",
    "    \"v1alpha1\": \"../data/final/v1alpha1\",\n",
    "}\n",
    "\n",
    "def extract_and_save(file_list, out_dir):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    for f in file_list:\n",
    "        print(f\"Processing {f}...\")\n",
    "        try:\n",
    "            ddf = dd.read_parquet(f, columns=['sha', 'commit', 'repository_full_name'], blocksize=\"128MB\")\n",
    "\n",
    "\n",
    "            def extract(df):\n",
    "                df['author_date'] = df['commit'].apply(lambda x: x['author']['date'])\n",
    "                return df[['sha', 'author_date', 'repository_full_name']]\n",
    "\n",
    "            ddf = ddf.map_partitions(\n",
    "                extract,\n",
    "                meta={'sha': 'object', 'author_date': 'object', 'repository_full_name': 'object'}\n",
    "            )\n",
    "\n",
    "  \n",
    "            ddf = ddf.map_partitions(lambda df: df.drop_duplicates(subset='sha'), meta=ddf._meta)\n",
    "\n",
    "\n",
    "            name = os.path.basename(f).replace(\".parquet\", \"\")\n",
    "            out_path = os.path.join(out_dir, f\"{name}_processed\")\n",
    "            ddf.to_parquet(out_path, overwrite=True)\n",
    "\n",
    " \n",
    "            ddf_check = dd.read_parquet(out_path)\n",
    "            if 'sha' not in ddf_check.columns:\n",
    "                print(f\"[MISSING] 'sha' column missing in saved file: {out_path}\")\n",
    "            else:\n",
    "                print(f\"[OK] 'sha' column exists in saved file: {out_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Failed to process {f}: {e}\")\n",
    "\n",
    "def combine_and_save(dir_path, final_out):\n",
    "    files = glob.glob(os.path.join(dir_path, \"*_processed\"))\n",
    "    if not files:\n",
    "        print(f\"[WARNING] No processed files found in {dir_path}\")\n",
    "        return\n",
    "\n",
    "    all_parquet_files = []\n",
    "    for d in files:\n",
    "\n",
    "        parquet_files = glob.glob(os.path.join(d, \"*.parquet\"))\n",
    "        if parquet_files:\n",
    "            all_parquet_files.extend(parquet_files)\n",
    "        else:\n",
    "            print(f\"[SKIP] No parquet files found in {d}\")\n",
    "\n",
    "    if not all_parquet_files:\n",
    "        print(f\"[ERROR] No valid parquet files to combine in {dir_path}\")\n",
    "        return\n",
    "\n",
    "\n",
    "    ddf = dd.read_parquet(all_parquet_files, columns=['sha', 'author_date', 'repository_full_name'])\n",
    "\n",
    "\n",
    "    ddf = ddf.set_index('sha', sorted=False, drop=False)\n",
    "    ddf = ddf.map_partitions(lambda df: df[~df.index.duplicated(keep='first')])\n",
    "    ddf = ddf.reset_index(drop=True)\n",
    "\n",
    "    os.makedirs(final_out, exist_ok=True)\n",
    "    ddf.to_parquet(final_out, overwrite=True)\n",
    "    print(f\"Combined data saved to {final_out}\")\n",
    "\n",
    "# v1\n",
    "extract_and_save(files_v1, processed_dirs['v1'])\n",
    "combine_and_save(processed_dirs['v1'], final_dirs['v1'])\n",
    "\n",
    "# v1beta1\n",
    "extract_and_save(files_v1beta1, processed_dirs['v1beta1'])\n",
    "combine_and_save(processed_dirs['v1beta1'], final_dirs['v1beta1'])\n",
    "\n",
    "# v1alpha1\n",
    "extract_and_save(files_v1alpha1, processed_dirs['v1alpha1'])\n",
    "combine_and_save(processed_dirs['v1alpha1'], final_dirs['v1alpha1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff1a3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.font_manager as font_manager\n",
    "\n",
    "def saveFigure(fig,fileName):\n",
    "    fig.savefig(fileName,bbox_inches='tight',dpi=100, pad_inches = 0)\n",
    "\n",
    "\n",
    "def get_font_properties(routePath=os.getcwd()):\n",
    "    \n",
    "    fontpath = routePath+'/NimbusSanL-Reg.otf'\n",
    "    prop = font_manager.FontProperties(fname=fontpath, size=16)\n",
    "    return prop\n",
    "\n",
    "def get_props_as_dict():\n",
    "    routePath=os.getcwd()\n",
    "    fontpath = routePath+'/NimbusSanL-Reg.otf'\n",
    "    return {\n",
    "        \"name\": fontpath,\n",
    "        \"size\": 26\n",
    "    }\n",
    "\n",
    "def get_alt_font_properties(type=\"san\",size=15):\n",
    "    routePath=os.getcwd()\n",
    "    if type == \"rom\":\n",
    "        fontpath = routePath+'/NimbusRomNo9L-Reg.otf'\n",
    "    else:\n",
    "        fontpath = routePath+'/NimbusSanL-Reg.otf'\n",
    "    prop = font_manager.FontProperties(fname=fontpath, size=size)\n",
    "    return prop\n",
    "\n",
    "def save_fig(ax, title):\n",
    "    ax.figure.savefig(title,  dpi=300,  bbox_inches='tight', format=\"pdf\", pad_inches = 0)\n",
    "\n",
    "\n",
    "fontsize = 17\n",
    "legend_fontsize = fontsize\n",
    "smallfontsize = fontsize -1\n",
    "bigfont = fontsize + 5\n",
    "\n",
    "prop = get_alt_font_properties(type=\"rom\",size=fontsize)\n",
    "prop_big = get_alt_font_properties(type=\"rom\",size=bigfont)\n",
    "prop_small = get_alt_font_properties(type=\"rom\",size=smallfontsize)\n",
    "prop_legend = get_alt_font_properties(type=\"rom\",size=legend_fontsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad414056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load combined commit data\n",
    "df_v1 = dd.read_parquet(\"../data/final/v1\").compute()\n",
    "df_v1beta1 = dd.read_parquet(\"../data/final/v1beta1\").compute()\n",
    "df_v1alpha1 = dd.read_parquet(\"../data/final/v1alpha1\").compute()\n",
    "\n",
    "# Convert commit dates to datetime\n",
    "for df in [df_v1, df_v1beta1, df_v1alpha1]:\n",
    "    df['author_date'] = pd.to_datetime(df['author_date'])\n",
    "\n",
    "# Get last commit per repository\n",
    "df_v1_last = df_v1.groupby('repository_full_name')['author_date'].max().reset_index()\n",
    "df_v1beta1_last = df_v1beta1.groupby('repository_full_name')['author_date'].max().reset_index()\n",
    "df_v1alpha1_last = df_v1alpha1.groupby('repository_full_name')['author_date'].max().reset_index()\n",
    "\n",
    "# Sort by date\n",
    "df_v1_last = df_v1_last.sort_values('author_date')\n",
    "df_v1beta1_last = df_v1beta1_last.sort_values('author_date')\n",
    "df_v1alpha1_last = df_v1alpha1_last.sort_values('author_date')\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.scatter(df_v1_last['author_date'], range(len(df_v1_last)), color='#1f77b4', s=20, label='v1')\n",
    "plt.scatter(df_v1beta1_last['author_date'], range(len(df_v1beta1_last)), color='#ff7f0e', s=20, label='v1beta1')\n",
    "plt.scatter(df_v1alpha1_last['author_date'], range(len(df_v1alpha1_last)), color='#2ca02c', s=20, label='v1alpha1')\n",
    "\n",
    "plt.xlabel(\"Last Commit Date\", fontproperties=prop)\n",
    "plt.ylabel(\"Repositories\", fontproperties=prop)\n",
    "plt.title(\"Last Commit Date for v1, v1beta1, and v1alpha1 Repositories\", fontproperties=prop)\n",
    "plt.yticks([], fontproperties=prop)  # hide y-axis ticks but keep font\n",
    "plt.xticks(fontproperties=prop)  # hide y-axis ticks but keep font\n",
    "plt.legend(prop=prop)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e08dee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load combined commit data\n",
    "df_v1 = dd.read_parquet(\"../data/final/v1\").compute()\n",
    "df_v1beta1 = dd.read_parquet(\"../data/final/v1beta1\").compute()\n",
    "df_v1alpha1 = dd.read_parquet(\"../data/final/v1alpha1\").compute()\n",
    "\n",
    "# Convert commit dates to datetime\n",
    "for df in [df_v1, df_v1beta1, df_v1alpha1]:\n",
    "    df['author_date'] = pd.to_datetime(df['author_date'])\n",
    "\n",
    "# Get last commit per repository by taking the last element\n",
    "df_v1_last = df_v1.sort_values('author_date').groupby('repository_full_name').tail(1)\n",
    "df_v1beta1_last = df_v1beta1.sort_values('author_date').groupby('repository_full_name').tail(1)\n",
    "df_v1alpha1_last = df_v1alpha1.sort_values('author_date').groupby('repository_full_name').tail(1)\n",
    "\n",
    "# Sort all for plotting\n",
    "df_v1_last = df_v1_last.sort_values('author_date')\n",
    "df_v1beta1_last = df_v1beta1_last.sort_values('author_date')\n",
    "df_v1alpha1_last = df_v1alpha1_last.sort_values('author_date')\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.scatter(df_v1_last['author_date'], range(len(df_v1_last)), color='#1f77b4', s=20, label='v1')\n",
    "plt.scatter(df_v1beta1_last['author_date'], range(len(df_v1beta1_last)), color='#ff7f0e', s=20, label='v1beta1')\n",
    "plt.scatter(df_v1alpha1_last['author_date'], range(len(df_v1alpha1_last)), color='#2ca02c', s=20, label='v1alpha1')\n",
    "\n",
    "plt.xlabel(\"Last Commit Date\", fontproperties=prop)\n",
    "plt.ylabel(\"Repositories\", fontproperties=prop)\n",
    "plt.title(\"Last Commit Date for v1, v1beta1, and v1alpha1 Repositories\", fontproperties=prop)\n",
    "plt.yticks([], fontproperties=prop)\n",
    "plt.legend(prop=prop)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217b8d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "\n",
    "# Load v1alpha1 commit data\n",
    "df_alpha = dd.read_parquet(\"../data/final/v1alpha1\").compute()\n",
    "\n",
    "# Convert commit dates to datetime\n",
    "df_alpha['author_date'] = pd.to_datetime(df_alpha['author_date'])\n",
    "\n",
    "# Get last commit per repository\n",
    "df_alpha_last = df_alpha.sort_values('author_date').groupby('repository_full_name').tail(1)\n",
    "\n",
    "# Show 10 samples\n",
    "sample_alpha = df_alpha_last[['repository_full_name', 'author_date']].sample(10, random_state=42)\n",
    "print(sample_alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3694325",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Make sure author_date is datetime\n",
    "df_alpha_last['author_date'] = pd.to_datetime(df_alpha_last['author_date'])\n",
    "\n",
    "# Aggregate by month (year-month)\n",
    "df_alpha_last['year_month'] = df_alpha_last['author_date'].dt.to_period('M')\n",
    "repo_counts = df_alpha_last.groupby('year_month').size().reset_index(name='num_repos')\n",
    "\n",
    "# Convert year_month back to datetime for plotting\n",
    "repo_counts['year_month'] = repo_counts['year_month'].dt.to_timestamp()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.bar(repo_counts['year_month'], repo_counts['num_repos'], color='#2ca02c', width=20)  # width in days\n",
    "\n",
    "plt.xlabel(\"Month of Last Commit\", fontproperties=prop)\n",
    "plt.ylabel(\"Number of Repositories\", fontproperties=prop)\n",
    "plt.title(\"Number of v1alpha1 Repositories by Month of Last Commit\", fontproperties=prop)\n",
    "plt.xticks(rotation=45, ha='right', fontproperties=prop)\n",
    "plt.yticks(fontproperties=prop)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cb6aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assume these DataFrames exist and have columns:\n",
    "# 'repository_full_name', 'author_date'\n",
    "# df_v1_last, df_beta_last, df_alpha_last\n",
    "\n",
    "# Convert author_date to datetime if not already\n",
    "for df in [df_v1_last, df_v1beta1_last, df_alpha_last]:\n",
    "    df['author_date'] = pd.to_datetime(df['author_date'])\n",
    "\n",
    "# Sort dates for CDF\n",
    "df_v1_sorted = df_v1_last['author_date'].sort_values()\n",
    "df_beta_sorted = df_v1beta1_last['author_date'].sort_values()\n",
    "df_alpha_sorted = df_alpha_last['author_date'].sort_values()\n",
    "\n",
    "# Compute CDF values\n",
    "cdf_v1 = pd.Series(range(1, len(df_v1_sorted)+1)) / len(df_v1_sorted)\n",
    "cdf_beta = pd.Series(range(1, len(df_beta_sorted)+1)) / len(df_beta_sorted)\n",
    "cdf_alpha = pd.Series(range(1, len(df_alpha_sorted)+1)) / len(df_alpha_sorted)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(df_v1_sorted, cdf_v1, label='v1', color='#1f77b4')\n",
    "plt.plot(df_beta_sorted, cdf_beta, label='beta', color='#ff7f0e')\n",
    "plt.plot(df_alpha_sorted, cdf_alpha, label='alpha', color='#2ca02c')\n",
    "\n",
    "plt.xlabel(\"Last Commit Date\")\n",
    "plt.ylabel(\"Cumulative Fraction of Repositories\")\n",
    "plt.title(\"CDF of Last Commit Dates per API Version\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f47ba35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "prop = prop_big\n",
    "# Ensure dates are tz-aware\n",
    "for df in [df_v1_last, df_v1beta1_last, df_alpha_last]:\n",
    "    df['author_date'] = pd.to_datetime(df['author_date'])\n",
    "    if df['author_date'].dt.tz is None:\n",
    "        df['author_date'] = df['author_date'].dt.tz_localize(pytz.UTC)\n",
    "\n",
    "# Sort dates\n",
    "df_v1_sorted = df_v1_last['author_date'].sort_values()\n",
    "df_beta_sorted = df_v1beta1_last['author_date'].sort_values()\n",
    "df_alpha_sorted = df_alpha_last['author_date'].sort_values()\n",
    "\n",
    "# Compute survival function\n",
    "sf_v1 = 1 - pd.Series(range(1, len(df_v1_sorted)+1)) / len(df_v1_sorted)\n",
    "sf_beta = 1 - pd.Series(range(1, len(df_beta_sorted)+1)) / len(df_beta_sorted)\n",
    "sf_alpha = 1 - pd.Series(range(1, len(df_alpha_sorted)+1)) / len(df_alpha_sorted)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(df_v1_sorted, sf_v1, label='v1', color='#1f77b4')\n",
    "plt.plot(df_beta_sorted, sf_beta, label='beta (β)', color='#ff7f0e')\n",
    "plt.plot(df_alpha_sorted, sf_alpha, label='alpha (α)', color='#2ca02c')\n",
    "\n",
    "#plt.xlabel(\"Date\", fontproperties=prop)\n",
    "plt.ylabel(\"Repositories Active After Date (%)\",   fontproperties=prop)\n",
    "#plt.title(\"Repository Activity Survival Function\",  fontproperties=prop)\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "# Last year reference\n",
    "one_year_ago = datetime.now(pytz.UTC) - timedelta(days=365)\n",
    "plt.axvline(one_year_ago, color='black', linestyle='--', alpha=0.5)\n",
    "plt.text(one_year_ago, 0.12, \"One year ago\", rotation=90, va='bottom', ha='right', color='black', fontproperties=prop_small)\n",
    "# Create a “box” legend with percentages\n",
    "percent_last_year = {\n",
    "    'v1': (df_v1_sorted > one_year_ago).mean() * 100,\n",
    "    'β': (df_beta_sorted > one_year_ago).mean() * 100,\n",
    "    'α': (df_alpha_sorted > one_year_ago).mean() * 100\n",
    "}\n",
    "\n",
    "# Add text box in axes coordinates\n",
    "textstr = '\\n'.join([f\"{k}: {v:.1f}%\" for k,v in percent_last_year.items()])\n",
    "props = dict(boxstyle='round', facecolor='white', alpha=0.8)\n",
    "\n",
    "# Place the text box in the top-right corner\n",
    "plt.text(\n",
    "    0.97, 0.97,      # x, y in axes coordinates (0-1)\n",
    "    textstr,\n",
    "    transform=plt.gca().transAxes,\n",
    "    \n",
    "    ha='right',       # horizontal alignment\n",
    "    va='top',         # vertical alignment\n",
    "    bbox=props,\n",
    "     fontproperties=prop,\n",
    ")\n",
    "plt.legend(loc='lower left', prop=prop)\n",
    "plt.tight_layout()\n",
    "plt.xticks(fontproperties=prop)\n",
    "plt.yticks(fontproperties=prop)\n",
    "plt.savefig(\"./figures/repositoriy_activity_survival.svg\", dpi=300, bbox_inches=\"tight\", pad_inches=0)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc97516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define cutoff date (one year ago from \"now\")\n",
    "one_year_ago = datetime.now(pytz.UTC) - timedelta(days=365)\n",
    "\n",
    "# Filter each version\n",
    "df_v1_active = df_v1_last[df_v1_last['author_date'] > one_year_ago].copy()\n",
    "df_beta_active = df_v1beta1[df_v1beta1['author_date'] > one_year_ago].copy()\n",
    "df_alpha_active = df_alpha_last[df_alpha_last['author_date'] > one_year_ago].copy()\n",
    "\n",
    "# Show sizes\n",
    "print(\"Active v1 repositories:\", len(df_v1_active))\n",
    "print(\"Active beta repositories:\", len(df_beta_active))\n",
    "print(\"Active alpha repositories:\", len(df_alpha_active))\n",
    "\n",
    "# Peek into the results\n",
    "print(df_alpha_active.head(10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
