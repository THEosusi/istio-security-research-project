{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee2d39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#auth\n",
    "file_path = \"../data/repositoryinfo/peer_auth_v1_repos.parquet\"\n",
    "\n",
    "df_peer_auth_v1 = pd.read_parquet(file_path)\n",
    "df_peer_auth_v1 \n",
    "\n",
    "file_path = \"../data/repositoryinfo/req_auth_v1_repos.parquet\"\n",
    "df_req_auth_v1 = pd.read_parquet(file_path)\n",
    "df_req_auth_v1\n",
    "\n",
    "file_path = \"../data/repositoryinfo/peer_auth_v1beta1_repos.parquet\"\n",
    "df_peer_auth_v1beta1 = pd.read_parquet(file_path)\n",
    "df_peer_auth_v1beta1\n",
    "\n",
    "file_path = \"../data/repositoryinfo/req_auth_v1beta1_repos.parquet\"\n",
    "df_req_auth_v1beta1 = pd.read_parquet(file_path)\n",
    "df_req_auth_v1beta1\n",
    "\n",
    "file_path = \"../data/repositoryinfo/peer_auth_v1alpha1_repos.parquet\"\n",
    "df_peer_auth_v1alpha1 = pd.read_parquet(file_path)\n",
    "df_peer_auth_v1alpha1\n",
    "\n",
    "file_path = \"../data/repositoryinfo/req_auth_v1alpha1_repos.parquet\"\n",
    "df_req_auth_v1alpha1 = pd.read_parquet(file_path)\n",
    "df_req_auth_v1alpha1\n",
    "\n",
    "\n",
    "#authz  \n",
    "file_path = \"../data/repositoryinfo/http_authz_v1_repos.parquet\"\n",
    "\n",
    "df_http_authz_v1 = pd.read_parquet(file_path)\n",
    "df_http_authz_v1\n",
    "\n",
    "file_path = \"../data/repositoryinfo/http_authz_v1beta1_repos.parquet\"\n",
    "df_http_authz_v1beta1 = pd.read_parquet(file_path)\n",
    "df_http_authz_v1beta1\n",
    "\n",
    "file_path = \"../data/repositoryinfo/tcp_authz_v1_repos.parquet\"\n",
    "df_tcp_authz_v1 = pd.read_parquet(file_path)\n",
    "df_tcp_authz_v1\n",
    "\n",
    "file_path = \"../data/repositoryinfo/tcp_authz_v1beta1_repos.parquet\"\n",
    "df_tcp_authz_v1beta1 = pd.read_parquet(file_path)\n",
    "df_tcp_authz_v1beta1\n",
    "\n",
    "file_path = \"../data/repositoryinfo/jwt_authz_v1_repos.parquet\"\n",
    "df_jwt_authz_v1 = pd.read_parquet(file_path)\n",
    "df_jwt_authz_v1\n",
    "\n",
    "file_path = \"../data/repositoryinfo/jwt_authz_v1beta1_repos.parquet\"\n",
    "df_jwt_authz_v1beta1 = pd.read_parquet(file_path)\n",
    "df_jwt_authz_v1beta1\n",
    "\n",
    "file_path = \"../data/repositoryinfo/provider_authz_v1_repos.parquet\"\n",
    "df_provider_authz_v1 = pd.read_parquet(file_path)\n",
    "df_provider_authz_v1\n",
    "\n",
    "file_path = \"../data/repositoryinfo/provider_authz_v1beta1_repos.parquet\"\n",
    "df_provider_authz_v1beta1 = pd.read_parquet(file_path)\n",
    "df_provider_authz_v1beta1\n",
    "\n",
    "file_path = \"../data/repositoryinfo/ingress_authz_ip_v1_repos.parquet\"\n",
    "df_ingress_authz_ip_v1 = pd.read_parquet(file_path)\n",
    "df_ingress_authz_ip_v1\n",
    "\n",
    "file_path = \"../data/repositoryinfo/ingress_authz_ip_v1beta1_repos.parquet\"\n",
    "df_ingress_authz_ip_v1beta1 = pd.read_parquet(file_path)\n",
    "df_ingress_authz_ip_v1beta1\n",
    "\n",
    "file_path= \"../data/repositoryinfo/ingress_authz_remote_ip_v1_repos.parquet\"\n",
    "df_ingress_authz_remote_ip_v1 = pd.read_parquet(file_path)\n",
    "df_ingress_authz_remote_ip_v1\n",
    "\n",
    "file_path = \"../data/repositoryinfo/ingress_authz_remote_ip_v1beta1_repos.parquet\"\n",
    "df_ingress_authz_remote_ip_v1beta1 = pd.read_parquet(file_path)\n",
    "df_ingress_authz_remote_ip_v1beta1\n",
    "\n",
    "\n",
    "file_path = \"../data/repositoryinfo/any_authz_v1alpha1_repos.parquet\"\n",
    "df_any_authz_v1alpha1 = pd.read_parquet(file_path)\n",
    "df_any_authz_v1alpha1\n",
    "\n",
    "\n",
    "\n",
    "#mtls\n",
    "file_path = \"../data/repositoryinfo/mtls_strict_v1_repos.parquet\"\n",
    "\n",
    "df_strict_v1 = pd.read_parquet(file_path)\n",
    "df_strict_v1\n",
    "\n",
    "file_path = \"../data/repositoryinfo/mtls_permissive_v1_repos.parquet\"\n",
    "\n",
    "df_permissive_v1 = pd.read_parquet(file_path)\n",
    "df_permissive_v1\n",
    "\n",
    "file_path = \"../data/repositoryinfo/mtls_disable_v1_repos.parquet\"\n",
    "\n",
    "df_disable_v1 = pd.read_parquet(file_path)\n",
    "df_disable_v1\n",
    "\n",
    "\n",
    "file_path = \"../data/repositoryinfo/mtls_strict_v1beta1_repos.parquet\"\n",
    "\n",
    "df_strict_v1beta1 = pd.read_parquet(file_path)\n",
    "df_strict_v1beta1\n",
    "\n",
    "file_path = \"../data/repositoryinfo/mtls_permissive_v1beta1_repos.parquet\"\n",
    "\n",
    "df_permissive_v1beta1 = pd.read_parquet(file_path)\n",
    "df_permissive_v1beta1\n",
    "\n",
    "file_path = \"../data/repositoryinfo/mtls_disable_v1beta1_repos.parquet\"\n",
    "\n",
    "df_disable_v1beta1 = pd.read_parquet(file_path)\n",
    "df_disable_v1beta1\n",
    "\n",
    "\n",
    "file_path = \"../data/repositoryinfo/mtls_strict_v1alpha1_repos.parquet\"\n",
    "\n",
    "df_strict_v1alpha1 = pd.read_parquet(file_path)\n",
    "df_strict_v1alpha1\n",
    "\n",
    "file_path = \"../data/repositoryinfo/mtls_permissive_v1alpha1_repos.parquet\"\n",
    "\n",
    "df_permissive_v1alpha1 = pd.read_parquet(file_path)\n",
    "df_permissive_v1alpha1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4d08e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.font_manager as font_manager\n",
    "\n",
    "def saveFigure(fig,fileName):\n",
    "    fig.savefig(fileName,bbox_inches='tight',dpi=100, pad_inches = 0)\n",
    "\n",
    "\n",
    "def get_font_properties(routePath=os.getcwd()):\n",
    "    \n",
    "    fontpath = routePath+'/NimbusSanL-Reg.otf'\n",
    "    prop = font_manager.FontProperties(fname=fontpath, size=16)\n",
    "    return prop\n",
    "\n",
    "def get_props_as_dict():\n",
    "    routePath=os.getcwd()\n",
    "    fontpath = routePath+'/NimbusSanL-Reg.otf'\n",
    "    return {\n",
    "        \"name\": fontpath,\n",
    "        \"size\": 26\n",
    "    }\n",
    "\n",
    "def get_alt_font_properties(type=\"san\",size=15):\n",
    "    routePath=os.getcwd()\n",
    "    if type == \"rom\":\n",
    "        fontpath = routePath+'/NimbusRomNo9L-Reg.otf'\n",
    "    else:\n",
    "        fontpath = routePath+'/NimbusSanL-Reg.otf'\n",
    "    prop = font_manager.FontProperties(fname=fontpath, size=size)\n",
    "    return prop\n",
    "\n",
    "def save_fig(ax, title):\n",
    "    ax.figure.savefig(title,  dpi=300,  bbox_inches='tight', format=\"pdf\", pad_inches = 0)\n",
    "\n",
    "\n",
    "fontsize = 17\n",
    "legend_fontsize = fontsize\n",
    "smallfontsize = fontsize -1\n",
    "\n",
    "prop = get_alt_font_properties(type=\"rom\",size=fontsize)\n",
    "prop_small = get_alt_font_properties(type=\"rom\",size=smallfontsize)\n",
    "prop_legend = get_alt_font_properties(type=\"rom\",size=legend_fontsize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4450198a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_mtls = pd.concat([df_strict_v1, df_permissive_v1, df_disable_v1, df_strict_v1beta1, df_permissive_v1beta1, df_disable_v1beta1, df_strict_v1alpha1,df_permissive_v1alpha1], ignore_index=True)\n",
    "df_all_auth = pd.concat([df_peer_auth_v1,df_req_auth_v1,df_peer_auth_v1beta1,df_req_auth_v1beta1,df_peer_auth_v1alpha1,df_req_auth_v1alpha1 ], ignore_index=True)\n",
    "df_all_authz = pd.concat([df_http_authz_v1, df_http_authz_v1beta1, df_tcp_authz_v1,df_tcp_authz_v1beta1,df_jwt_authz_v1, df_jwt_authz_v1beta1, df_provider_authz_v1,df_provider_authz_v1beta1,df_ingress_authz_ip_v1,df_ingress_authz_ip_v1beta1,df_ingress_authz_remote_ip_v1,df_ingress_authz_remote_ip_v1beta1,df_any_authz_v1alpha1], ignore_index=True)\n",
    "\n",
    "df_all_mtls_unique = df_all_mtls.drop_duplicates(subset=\"full_name\")\n",
    "df_all_auth_unique = df_all_auth.drop_duplicates(subset=\"full_name\")\n",
    "df_all_authz_unique = df_all_authz.drop_duplicates(subset=\"full_name\")\n",
    "\n",
    "\n",
    "\n",
    "df_mtls_auth = pd.merge(df_all_mtls_unique, df_all_auth_unique, on=\"full_name\", how=\"inner\")\n",
    "df_mtls_authz = pd.merge(df_all_mtls_unique, df_all_authz_unique, on=\"full_name\", how=\"inner\")\n",
    "df_auth_authz = pd.merge(df_all_auth_unique, df_all_authz_unique, on=\"full_name\", how=\"inner\")\n",
    "df_all = df_all_mtls_unique.merge(df_all_auth_unique, on=\"full_name\").merge(df_all_authz_unique, on=\"full_name\")\n",
    "\n",
    "print(\"mtls ∩ auth:\", len(df_mtls_auth))\n",
    "print(\"mtls ∩ authz:\", len(df_mtls_authz))\n",
    "print(\"auth ∩ authz:\", len(df_auth_authz))\n",
    "print(\"mtls ∩ auth ∩ authz:\", len(df_all))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6bf357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file_path = \"../data/repositoryinfo/all_all_repos.parquet\"\n",
    "\n",
    "df_istio = pd.read_parquet(file_path)\n",
    "df_istio.drop_duplicates(subset=\"full_name\")\n",
    "print(\"all istio usage\", len(df_istio))\n",
    "print(\"all istio usage\", len(df_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e141f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_istio.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963d6434",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_strict_v1only = df_strict_v1[\n",
    "    ~df_strict_v1[\"full_name\"].isin(df_strict_v1beta1[\"full_name\"])\n",
    "    & ~df_strict_v1[\"full_name\"].isin(df_strict_v1alpha1[\"full_name\"])\n",
    "]\n",
    "df_strict_v1= df_strict_v1only\n",
    "\n",
    "# Permissive v1 only: entries in df_permissive_v1 not present in v1beta1 or v1alpha1\n",
    "df_permissive_v1only = df_permissive_v1[\n",
    "    ~df_permissive_v1[\"full_name\"].isin(df_permissive_v1beta1[\"full_name\"])\n",
    "    & ~df_permissive_v1[\"full_name\"].isin(df_permissive_v1alpha1[\"full_name\"])\n",
    "]\n",
    "df_permissive_v1= df_permissive_v1only\n",
    "\n",
    "# Disable v1 only: entries in df_disable_v1 not present in v1beta1\n",
    "df_disable_v1only = df_disable_v1[\n",
    "    ~df_disable_v1[\"full_name\"].isin(df_disable_v1beta1[\"full_name\"])\n",
    "]\n",
    "df_disable_v1= df_disable_v1only\n",
    "df_all = pd.concat([df_strict_v1, df_permissive_v1, df_disable_v1, df_strict_v1beta1, df_permissive_v1beta1, df_disable_v1beta1, df_strict_v1alpha1,df_permissive_v1alpha1], ignore_index=True)\n",
    "df_v1=pd.concat([df_strict_v1, df_permissive_v1, df_disable_v1], ignore_index=True)\n",
    "df_v1beta1=pd.concat([df_strict_v1beta1, df_permissive_v1beta1, df_disable_v1beta1], ignore_index=True)\n",
    "df_v1alpha1=pd.concat([df_strict_v1alpha1,df_permissive_v1alpha1], ignore_index=True)\n",
    "df_strict=pd.concat([df_strict_v1, df_strict_v1beta1, df_strict_v1alpha1], ignore_index=True)\n",
    "df_permissive=pd.concat([df_permissive_v1, df_permissive_v1beta1, df_permissive_v1alpha1], ignore_index=True)\n",
    "df_disable=pd.concat([df_disable_v1, df_disable_v1beta1], ignore_index=True)\n",
    "\n",
    "df_all_unique = df_all.drop_duplicates(subset=\"full_name\")\n",
    "df_v1_unique = df_v1.drop_duplicates(subset=\"full_name\")\n",
    "df_v1beta1_unique = df_v1beta1.drop_duplicates(subset=\"full_name\")\n",
    "df_v1alpha1_unique = df_v1alpha1.drop_duplicates(subset=\"full_name\")\n",
    "df_strict_unique = df_strict.drop_duplicates(subset=\"full_name\")\n",
    "df_permissive_unique = df_permissive.drop_duplicates(subset=\"full_name\")\n",
    "df_disable_unique = df_disable.drop_duplicates(subset=\"full_name\")\n",
    "# Create sets for each version\n",
    "v1_set = set(df_v1_unique[\"full_name\"])\n",
    "v1beta1_set = set(df_v1beta1_unique[\"full_name\"])\n",
    "v1alpha1_set = set(df_v1alpha1_unique[\"full_name\"])\n",
    "\n",
    "# Disjoint sets\n",
    "v1_only_names = v1_set - v1beta1_set - v1alpha1_set\n",
    "v1beta1_only_names = v1beta1_set - v1_set - v1alpha1_set\n",
    "v1alpha1_only_names = v1alpha1_set - v1_set - v1beta1_set\n",
    "\n",
    "# Overlap sets\n",
    "v1_and_v1beta1_names = (v1_set & v1beta1_set) - v1alpha1_set\n",
    "v1_and_v1alpha1_names = (v1_set & v1alpha1_set) - v1beta1_set\n",
    "v1beta1_and_v1alpha1_names = (v1beta1_set & v1alpha1_set) - v1_set\n",
    "all_three_names = v1_set & v1beta1_set & v1alpha1_set\n",
    "\n",
    "# Create DataFrames for each set\n",
    "df_v1_only = df_v1_unique[df_v1_unique[\"full_name\"].isin(v1_only_names)]\n",
    "df_v1beta1_only = df_v1beta1_unique[df_v1beta1_unique[\"full_name\"].isin(v1beta1_only_names)]\n",
    "df_v1alpha1_only = df_v1alpha1_unique[df_v1alpha1_unique[\"full_name\"].isin(v1alpha1_only_names)]\n",
    "\n",
    "df_v1_and_v1beta1 = df_v1_unique[df_v1_unique[\"full_name\"].isin(v1_and_v1beta1_names)]\n",
    "df_v1_and_v1alpha1 = df_v1_unique[df_v1_unique[\"full_name\"].isin(v1_and_v1alpha1_names)]\n",
    "df_v1beta1_and_v1alpha1 = df_v1beta1_unique[df_v1beta1_unique[\"full_name\"].isin(v1beta1_and_v1alpha1_names)]\n",
    "df_all_three = df_v1_unique[df_v1_unique[\"full_name\"].isin(all_three_names)]\n",
    "\n",
    "# Print counts for each group\n",
    "print(\"v1 only:\", len(df_v1_only))\n",
    "print(\"v1beta1 only:\", len(df_v1beta1_only))\n",
    "print(\"v1alpha1 only:\", len(df_v1alpha1_only))\n",
    "print(\"v1 and v1beta1 only:\", len(df_v1_and_v1beta1))\n",
    "print(\"v1 and v1alpha1 only:\", len(df_v1_and_v1alpha1))\n",
    "print(\"v1beta1 and v1alpha1 only:\", len(df_v1beta1_and_v1alpha1))\n",
    "print(\"all three:\", len(df_all_three))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1840c15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_strict_v1only = df_strict_v1[\n",
    "    ~df_strict_v1[\"full_name\"].isin(df_strict_v1beta1[\"full_name\"])\n",
    "    & ~df_strict_v1[\"full_name\"].isin(df_strict_v1alpha1[\"full_name\"])\n",
    "]\n",
    "df_strict_v1= df_strict_v1only\n",
    "\n",
    "# Permissive v1 only: entries in df_permissive_v1 not present in v1beta1 or v1alpha1\n",
    "df_permissive_v1only = df_permissive_v1[\n",
    "    ~df_permissive_v1[\"full_name\"].isin(df_permissive_v1beta1[\"full_name\"])\n",
    "    & ~df_permissive_v1[\"full_name\"].isin(df_permissive_v1alpha1[\"full_name\"])\n",
    "]\n",
    "df_permissive_v1= df_permissive_v1only\n",
    "\n",
    "# Disable v1 only: entries in df_disable_v1 not present in v1beta1\n",
    "df_disable_v1only = df_disable_v1[\n",
    "    ~df_disable_v1[\"full_name\"].isin(df_disable_v1beta1[\"full_name\"])\n",
    "]\n",
    "df_disable_v1= df_disable_v1only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adec75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Counts\n",
    "count_istio = len(df_istio)\n",
    "count_mtls = len(df_all_mtls_unique)\n",
    "count_auth = len(df_all_auth_unique)\n",
    "count_mtls_auth = len(df_mtls_auth)\n",
    "\n",
    "# Reference total (7435 == 100%)\n",
    "total = 7435  \n",
    "\n",
    "labels = [\n",
    "    \"Istio usage\",\n",
    "    \"mTLS\",\n",
    "    \"Auth\",\n",
    "    \"mTLS ∩ Auth\"\n",
    "]\n",
    "counts = [\n",
    "    count_istio,\n",
    "    count_mtls,\n",
    "    count_auth,\n",
    "    count_mtls_auth\n",
    "]\n",
    "\n",
    "# Compute percentages\n",
    "percentages = [(c / total) * 100 for c in counts]\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "bars = plt.bar(labels, counts, color=[\"gray\", \"blue\", \"green\", \"purple\"])\n",
    "plt.ylabel(\"Number of Applications\")\n",
    "#plt.title(\"Usage of security features in Istio repositories\")\n",
    "\n",
    "# Add counts + percentages on top of each bar\n",
    "for bar, pct in zip(bars, percentages):\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width()/2, \n",
    "        height, \n",
    "        f\"{int(height)} ({pct:.1f}%)\",  # show both count and percentage\n",
    "        ha='center', va='bottom', fontsize=10,\n",
    "        fontproperties=prop\n",
    "    )\n",
    "\n",
    "plt.savefig(\"./figures/general_usage.svg\", dpi=300, bbox_inches=\"tight\", pad_inches = 0)  \n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcb1898",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate counts for each Istio version\n",
    "count_v1 = len(df_strict_v1) + len(df_permissive_v1) + len(df_disable_v1)\n",
    "count_v1beta1 = len(df_strict_v1beta1) + len(df_permissive_v1beta1) + len(df_disable_v1beta1)\n",
    "count_v1alpha1 = len(df_strict_v1alpha1) + len(df_permissive_v1alpha1)\n",
    "\n",
    "labels = [\"Istio v1\", \"Istio v1beta1\", \"Istio v1alpha1\"]\n",
    "counts = [count_v1, count_v1beta1, count_v1alpha1]\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "bars = plt.bar(labels, counts, color=[\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\"])\n",
    "plt.ylabel(\"Number of Applications\",         fontproperties=prop\n",
    ")\n",
    "#plt.title(\"Istio Usage by Version\")\n",
    "\n",
    "# Add numbers on top of each bar\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, height, f\"{int(height)}\", ha='center', va='bottom', fontsize=11,         fontproperties=prop\n",
    ")\n",
    "plt.xticks(fontproperties=prop)  # <--- affects the bar category labels\n",
    "plt.yticks(fontproperties=prop)\n",
    "plt.savefig(\"./figures/istio by version.svg\", dpi=300, bbox_inches=\"tight\", pad_inches = 0)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc2a031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total unique Istio usage across all versions\n",
    "df_all_versions = pd.concat([\n",
    "    df_strict_v1, df_permissive_v1, df_disable_v1,\n",
    "    df_strict_v1beta1, df_permissive_v1beta1, df_disable_v1beta1,\n",
    "    df_strict_v1alpha1, df_permissive_v1alpha1\n",
    "], ignore_index=True)\n",
    "\n",
    "df_all_versions_unique = df_all_versions.drop_duplicates(subset=\"full_name\")\n",
    "print(\"Total unique Istio usage (all versions):\", len(df_all_versions_unique))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
